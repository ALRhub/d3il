_target_: agents.bet_mlp_vision_agent.BetMLP_Agent
_recursive_: false

model:
  _target_: agents.bet_mlp_vision_agent.Bet_Vision_Policy
  _recursive_: false

  visual_input: True
  device: ${device}

  model:
    _target_: agents.bet_mlp_vision_agent.BeTPolicy
    _recursive_: false

    obs_dim: 128 #${obs_dim}
    act_dim: ${action_dim}
    vocab_size: 64
    predict_offsets: True
    device: ${device}

    offset_loss_scale: 1.0
    focal_loss_gamma: 2.0

    model:
      _target_: agents.models.common.mlp.ResidualMLPNetwork
      input_dim: 128 #${obs_dim}
      hidden_dim: ${hidden_dim}
      num_hidden_layers: ${num_hidden_layers}
  #    output_dim: ${action_dim}
      dropout: 0
      activation: 'Mish'
      use_spectral_norm: false
      use_norm: False
      norm_style: 'BatchNorm'
      device: ${device}

  obs_encoder:
    _target_: agents.models.vision.multi_image_obs_encoder.MultiImageObsEncoder
    shape_meta: &shape_meta
      # acceptable types: rgb, low_dim
      obs:
        agentview_image:
          shape: [ 3, 96, 96 ]
          type: rgb
        in_hand_image:
          shape: [ 3, 96, 96 ]
          type: rgb
    #        robot_ee_pos:
    #          shape: [3]
    #          type default: low_dim
    #      robot0_eef_quat:
    #        shape: [4]
    #      robot0_gripper_qpos:
    #        shape: [2]
    #    action:
    #      shape: [10]

    rgb_model:
      _target_: agents.models.vision.model_getter.get_resnet
      input_shape: [ 3, 96, 96 ]
      output_size: 64
    resize_shape: null
    #    crop_shape: [ 84, 84 ]
    # constant center crop
    random_crop: False
    use_group_norm: True
    share_rgb_model: False
    imagenet_norm: True

obs_encoding_net:
  _target_: torch.nn.Identity
  output_dim: ${obs_dim}

action_ae:
  _target_: agents.models.bet.action_ae.discretizers.k_means.KMeansDiscretizer
  #num_bins: 14
  action_dim: ${action_dim}
  device: ${device}
  predict_offsets: True

optimization:
  _target_: torch.optim.AdamW
  lr: 1.0e-4
  betas: [0.95, 0.999]
  eps: 1.0e-8
  weight_decay: 1.0e-6

grad_norm_clip: 1.0

trainset: ${trainset}
valset: ${valset}

train_batch_size: ${train_batch_size}
val_batch_size: ${val_batch_size}
num_workers: ${num_workers}
epoch: ${epoch}
device: ${device}
scale_data: ${scale_data}
window_size: ${window_size}
eval_every_n_epochs: ${eval_every_n_epochs}

